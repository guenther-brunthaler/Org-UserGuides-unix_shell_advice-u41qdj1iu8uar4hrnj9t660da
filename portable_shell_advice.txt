Portable Shell Advice
=====================
Guenther Brunthaler <gb@emgenxx69lwyn5ctlr4nl64ul.local>

/////
Format of THIS text: Character set is UTF-8, NFC (UNICODE normalization form "composed"), ASCII "LF" terminates every line. Long lines form flow-text paragraphs. Except when inside preformatted text blocks, between every two logically adjacent paragraphs an empty line is uses as a visual separator.
/////

This document tries to provide useful information about portable shell programming and standard utility usage.


printf can convert characters to ASCII codes or UNICODE code points
-------------------------------------------------------------------

----
$ printf '%d\n' "'A'"
65
$ printf '%#x\n' "'€'"
0x20ac
----

Note that printf does not interpret strings simply as bytes, but rather converts them into wchar_t (depending on the user's locale) and then outputs the numeric value of the first wide character.


printf can expand "typical" escape sequences
--------------------------------------------

----
$ printf '%b\n' "This ist tab-separated \033[32;5mGREEN\tBLINKING\033[0m text."
This ist tab-separated GREEN    BLINKING text.
$ man console_codes # Show info about available terminal escape sequences.
----


Avoid the assignment-feature of "local"
---------------------------------------

'local' is syntactically a normal command rather than an assignment which would treated specially be the shell.

This makes a difference in whether whitespace in the expanded arguments need be quoted or not:

----
v='a string with whitespace'

# This is OK because it is a shell assignment which does no word splitting:
local v2
v2=$v

# This will fail because "local" expects every assignment
# to be specified as a normal argument to the command:
local v2=$v

# This will work again:
local "v2=$v"
----

In addition to what has been said above, note that "local" is not a feature defined by POSIX, although all modern Bourne shell descendants seem to implement it.

It might be wise to avoid the "local var=initial"-construct completely, because at least in the "dash"-documentation, the assignment-feature of "local" is not mentioned in the man page (even though it is implemented).


Don't expect local variables to be initialized
----------------------------------------------

----
# Incorrect:
local out
for arg
   out=$out$arg
done
echo $out
----

This is not portable because $out is never initialized explicitly. In order to initialize the variable to an empty string, use either

----
local out=
----

(which is less portable) or

----
local out
out=
----


The "POSIX" and "C" locales are the same
----------------------------------------

I used to believe that the "POSIX" locale guarantees ASCII characters set where the "C" locale may only support a subset of ASCII.

However, the POSIX standard actually states that "C" and "POSIX" are just different name for the same locale.

There is no guarantee that the "POSIX" (or "C") locale includes all ASCII characters.

Therefore, it is better to use "C" as a locale name, because it might work for non-POSIX systems as well.

Despite of what has been said above, in practice one can assume that the "C" locale provides either ASCII or EBCDIC as a character set.


Ranges in regular expressions can have unexpected elements
----------------------------------------------------------

Range matching seems to use the current locale's LC_COLLATE weights in order to determine whether a character is within a fiven RegEx range or not:

----
$ LC_CTYPE=de_DE.UTF8 LC_COLLATE=de_DE.UTF8 expr hällo : '[a-z]*'
6
$ LC_CTYPE=C LC_COLLATE=de_DE.UTF8 expr hällo : '[a-z]*'
1
$ LC_CTYPE=de_DE.UTF8 LC_COLLATE=C expr hällo : '[a-z]*'
1
----

In order to compare ASCII-ranges, it seems to be best to run the command with LC_CTYPE=C.

Even though the character set of locale "C" may actually be EBCDIC rather than ASCII, the relative collation weights will hopefully be the same, yielding the same results.


BRE operators '\|', '\+' and '\?' are non-POSIX extensions
----------------------------------------------------------

Those well-known operators in basic regular expressions are in fact GNU (and BusyBox) extensions.

POSIX does not define them!

The only operator which POSIX BREs support besides '*' is '\{m,n\}'.

{instead of} $ expr x"$string" : x'[0-9]\+'

{better write} $ expr x"$string" : x'[0-9]\{1,\}'

{instead of} $ expr x"$string" : x'[0-9]\?'

{better write} $ expr x"$string" : x'[0-9]\{0,\}'

{instead of} $ expr x"$string" : x'.*\(apple\|banana\)'

{better write} $ expr x"$string" : x'.*\(apple\)' \| x"$string" : x'.*\(banana\)'


BRE '^' and '$' are not allowed as anchors within captures
----------------------------------------------------------

On the other hand, this would be pretty useless anyway, as BREs do not support an "OR"-operator either. 

Also note that '^' and '$' *are* allowed as anchors in EREs.


BREs in "expr" cannot catch the value zero directly
---------------------------------------------------

When trying to verify that a numeric string $int is a valid integer, the following command would *not* be correct:

$ expr x"$int" : x'\(0\|[1-9][0-9]*\)$' > /dev/null && echo ok || echo bad

First of all, the use of '\|" in a BRE ist not portable.

But besides that, the test will produce a false negative if the value zero is tested.

This is because the ":" operator returns the contents of its first caption, which would be "0" in that case, but expr returns a non-zero return code if the final result is 0 (or null).

The following variant will fix both issues:

$ expr x"$int" = x0 \| x"$int" : x'[1-9][0-9]*$' > /dev/null && echo ok || echo bad

This replaces the non-portable BRE '\|'-operator by the expr '|'-operator and avoids captions alltogether.

And here is a solution for parsing an integer prefix $num from a $string:

$ string='16 MiB'
num=`expr x"$string" : '\(x0\)' \| x"$string" : '\(x[1-9][0-9]*\)' \| x`; num=${num#x}'"; test -z "$num" && echo "bad"


Be aware of locale-dependent behaviour of "sort"
------------------------------------------------

Not only does $LC_COLLATE influence the way strings are sorted.

But also does $LC_NUMERIC determine how numeric string prefixes are parsed if numeric sorting is used.


"grep" options -E and -F are specified by POSIX
-----------------------------------------------

By default, grep only uses BREs, which are pretty limited especially in that they lack an "OR"-operator.

However, "grep -E" changes REs in those tools to be EREs rather than BREs, and relying on support for those switches is portable.

Note that "egrep" and "fgrep" are not defined by POSIX, but "grep -E" and "grep -F" (which to the same) are.

Also note that the -r option of "sed" is a GNU extension. "sed" only supports BREs in a portable way.


Don't run a command with closed standard streams
------------------------------------------------

While it is possible to run a command like this

$ some_command <& - >& - 2>& -

the POSIX standard defines this as implementation-specific behaviour, and states that standard utilities are allowed to not behave as described in this case.

In other words, *never* run any program with one of the three standard streams closed. Always rather redirect to or from /dev/null instead.

The closing of descriptors is only intended for additional file descriptors which have been opened by the script itself.

Of course, any program is free to document that it supports being run with some of its file descriptor closed. However, this cannot be assumed without explicit documentation.


All commands in a pipeline run in separate subshells
----------------------------------------------------

Do not assume that any part in a pipeline is able to affect the variables of any other part of the pipeline or the process within which the pipeline has been started.

Consider this:

$ export v=1; { echo "2: v was $v" >& 2; v=2; } \
  | { echo "3: v was $v" >& 2; v=3; }; \
  echo "1: v is $v" >& 2
3: v was 1
2: v was 1
1: v is 1

While it is clear that "2" and "1" report $v as "1", one could have assumed that "3" would display "2". And, BTW, the "export" does not change anything. The output is the same as without it.

*No* part of a pipeline is run in the context of the invoking top-level shell, and all inherit their variables from the top-level shell, and not from any of the subshells (or external commands) in which the other commands of the same pipeline run.

The return status of the whole pipeline is that of the last command in the pipeline, it does not matter whether any of the other commands fail.

This also applies to the effect of "-e" - even though the subshell inherit its setting and may terminate prematurely because of an error, the top-level shell will not get any indication of that, except for the return code of the last of the commands, which will be the return code of the whole pipeline.


How to filter the output of a command but still get its return code
-------------------------------------------------------------------

Consider this:

if
	patch -i file.patch file 2>& 1 | grep -v ^patching >& 2
then
	echo "Patch was applied successfully."
else
	echo "Aborting - patch failed!"
	exit
fi

The intention of this code is to filter the output of "patch", suppressing any "patching..." messages, but copying any other messages that "patch" generated through to standard error.

Unfortunately this code does not work as intended, because not the return status from "patch" will be used as the condition for "if", but rather the return status of "grep"! See the above section about all commands in a pipeline running in separate subshells, and only the last one determining the exit status of the pipeline.

In order to fix things, we need to use separate subprocesses instead of pipelines. This will work:

until
	fifo=`mktemp -u -- "${TMPDIR:-/tmp}/fifo.XXXXXX"` \
	&& mkfifo -m 600 -- "$fifo"
do
	:
done
grep -v ^patching < "$fifo" >& 2 || true & filter=$!
patch file file.patch > "$fifo" 2>& 1; rc=$?
wait $filter
rm -- "$fifo"
if (exit $rc)
then
	echo "Patch was applied successfully."
else
	echo "Aborting - patch failed!"
	exit
fi

Or one could turn things around and run "patch" in the background process, filtering in the top-level shell process. This should work as well:

... [as in first version]
done
patch file file.patch > "$fifo" 2>& 1 & worker=$!
grep -v ^patching < "$fifo" >& 2
wait $worker; rc=$?
rm -- "$fifo"
if (exit $rc)
... [as in first version]


Use "command -v" rather than "which" or "type"
----------------------------------------------

Although "which" will usually gives you exactly the answer you were looking for, it is unfortunately not part of POSIX and should therefore not be used in portable shell scripts.

Historically "which" was available as an external shell script long before "command" or "type", but it never managed to be standardized (my guess: too many sighly different implementations).

Both "type" and "command" are definied by POSIX and must be implemented as shell built-ins.

However, "type" was not implemented in all UNIXes, and early versions had bugs regardings its return code.

After all, "command -v" seems to be the most portable way to check whether a command is available.

However, "command -v" does not necessarily return a path - in case of shell functions or built-ins it just prints its argument without a path or even an alias definition!

Therefore, it is best to ignore the output of "command -v" and just use its return code to determine whether a command is available or not.

Even though I could not manage to get "command -v" writing anything to standard error, most scripts seem to redirect stderr also. In other words,

----
if command -f "$some_command" > /dev/null 2>& 1
then
	# Just use it, don't try to figure out its executable path name.
	...
	"$some_command" some arguments
	...
else
	echo "Error: there is no '$some_command'!" >& 2
	false || exit
fi
----
